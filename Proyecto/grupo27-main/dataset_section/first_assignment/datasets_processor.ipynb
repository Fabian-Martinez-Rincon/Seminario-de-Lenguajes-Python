{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 align =\"center\"><img src=\"https://media.giphy.com/media/LMt9638dO8dftAjtco/giphy.gif\" style = \"height:38px\"/> Carga de datos <img src=\"https://media.giphy.com/media/TEdRZnV7l3S067fiGR/giphy.gif\" style = \"height:38px\"/></h1 >\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tarjetas de FiguRace se generan a partir de un conjunto de datos que deberán ser preparados previamente. Como parte del proyecto se deberá desarrollar un cuaderno de Jupyter Notebook que extraiga los datos necesarios para el juego de alguno de los datasets provistos y muestre en forma detallada el proceso realizado con los mismos . En el Anexo II se detallan los datasets que deberán utilizar para la aplicación y las modificaciones necesarias para luego guardarlo en un nuevo archivo en formato CSV. El juego deberá cargar esos archivos CSV para funcionar\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td> <h5 align=\"center\"><img src=\"https://media.giphy.com/media/F3IsWfsR1JMyNmL44Z/giphy.gif\" style = \"height:38px\" /> Spotify 2010 - 2019 Top 100 <img  src=\"https://media.giphy.com/media/F3IsWfsR1JMyNmL44Z/giphy.gif\" style = \"height:38px\" /></h5> </td> <td> <h5 align=\"center\"><img src=\"https://media.giphy.com/media/W55QKlBohHZS9RGOWJ/giphy.gif\" style = \"height:38px\" /> FIFA-21 Complete <img  src=\"https://media.giphy.com/media/W55QKlBohHZS9RGOWJ/giphy.gif\" style = \"height:38px\" /></h5> </td><td> <h5 align=\"center\"><img src=\"https://media.giphy.com/media/YOk7USZ9k8yF4R0yn3/giphy.gif\" style = \"height:38px\" /> Lagos Argentina - Hoja 1 <img  src=\"https://media.giphy.com/media/YOk7USZ9k8yF4R0yn3/giphy.gif\" style = \"height:38px\" /></h5> </td>\n",
    "\n",
    "\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    " \n",
    "Deberá adaptar los datos de la siguiente forma: <br>\n",
    "\n",
    "- Poner en `title case` los géneros musicales excepto las siglas EDM, DFW, UK, R&B y LGBTQ+ que deben ir en mayúsculas. Por ejemplo `dfw rap` debe ser transformado a `DFW Rap`.<br>\n",
    "\n",
    "- Considerar también la excepción `k-pop` que debe ser transformada a `K-Pop`.<br>\n",
    "\n",
    "- Se utilizarán como datos de las tarjetas `Top Genre`, `Year Released`, `BPM`, `Top Year` y `Artist Type`. Como dato a adivinar se utilizará `Artist`. Descartar el resto de las columnas.<br>\n",
    "\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Top Genre`, `Artist Type`, `Year Released`, `Top Year`, `BPM` y `Artist`<br>\n",
    "\n",
    "</td>\n",
    "<td>\n",
    " \n",
    "Deberá adaptar los datos de la siguiente forma:<br>\n",
    "\n",
    "- Reemplazar `Potential` por la siguiente escala conceptual:<br>\n",
    "  - Regular: Menos de 60<br>\n",
    "  - Bueno: Entre 60 y 79 (inclusive)<br>\n",
    "  - Muy bueno: Entre 80 y 89 (inclusive)<br>\n",
    "  - Sobresaliente: Desde 90 en adelante.<br>\n",
    "- Reemplazar el valor de `Position` por las posiciones en español. Por ejemplo `LB|CB` debe ser reemplazado por `Defensor izquierdo|Defensor central`<br>\n",
    "- Se utilizarán como datos de las tarjetas: `Age`, `Nationality`, `Position`, `Team` y `Potential`. Como dato a adivinar se utilizará `Name`. Descartar el resto de las columnas.<br>\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Team`, `Nationality`, `Position`, `Age`, `Potential` y `Name`.<br>\n",
    " \n",
    "</td>\n",
    " <td>\n",
    " \n",
    "\n",
    "Deberá adaptar los datos de la siguiente forma:<br>\n",
    "\n",
    "- Transformar las coordenadas en la columna `Coordenadas` a grados decimales.<br>\n",
    "- Se utilizarán como datos de las tarjetas: `Ubicación`, `Superficie (km²)`, `Profundidad máxima (m)`, `Profundidad media (m)`, `Coordenadas`. Como dato a adivinar se utilizará `Nombre`. Descartar el resto de las columnas.<br>\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Ubicación`, `Superficie (km²)`, `Profundidad máxima (m)`, `Profundidad media (m)`, `Coordenadas` y `Nombre`.<br>\n",
    " \n",
    "</td>\n",
    "</tr>\n",
    " \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaramos las constantes\n",
    "--------------------------\n",
    "\n",
    "- `UPPER_GENDERS` : Contiene la lista de palabras que tenemos que convertir completamente a mayuscula\n",
    "- `ALL_ORDEN_REMOVE` : El orden en el que tienen que quedar las columnas de los archivos\n",
    "- `ALL_NAMES_REMOVE` : Las columnas que tengo que dejar en el archivo, el resto las elimino\n",
    "- `NAMES_DATASETS` : Contiene el nombre de los datasets para procesarlos mas adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\fabian\\\\Desktop\\\\PysimpleGuy\\\\grupo27\\\\dataset_section'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constantes y variables globales\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "ORDEN_SPOTIFY = [\"Top Genre\", \"Artist Type\", \"Year Released\", \"Top Year\", \"BPM\" ,\"Artist\"]\n",
    "ORDEN_LAGOS = [\"Ubicación\", \"Superficie (km²)\", \"Profundidad máxima (m)\", \"Profundidad media (m)\", \"Coordenadas\"]\n",
    "ORDEN_FIFA21 = [\"Team\", \"Nationality\", \"Position\", \"Age\", \"Potential\" ,\"Name\"]\n",
    "ALL_ORDEN_REMOVE = [ORDEN_SPOTIFY,ORDEN_LAGOS,ORDEN_FIFA21]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "NAMES_REMOVE_SPOTIFY = [\"Top Genre\", \"Year Released\",\"BPM\", \"Top Year\", \"Artist Type\",\"Artist\"]\n",
    "NAMES_REMOVE_LAGOS = [\"Ubicación\", \"Superficie (km²)\", \"Profundidad máxima (m)\", \"Profundidad media (m)\", \"Coordenadas\"]\n",
    "NAMES_REMOVE_FIFA21 = [\"Age\", \"Nationality\", \"Position\", \"Team\" , \"Potential\",\"Name\"]\n",
    "ALL_NAMES_REMOVE = [NAMES_REMOVE_SPOTIFY,NAMES_REMOVE_LAGOS,NAMES_REMOVE_FIFA21]\n",
    "\n",
    "NAMES_DATASETS = [\"Spotify_2010-2019_Top_100.csv\",\"Lagos_Argentina - Hoja_1.csv\",\"FIFA-21_Complete.csv\"]\n",
    "\n",
    "UPPER_GENDERS_SPOTIFY = [\"EDM\", \"DFW\", \"UK\", \"R&B\", \"LGBTQ+\"]\n",
    "\n",
    "POTENTIAL_TABLE_FIFA = {\n",
    "    90: 'Sobresaliente',\n",
    "    80: 'Muy bueno',\n",
    "    60: 'Bueno',\n",
    "    -1: 'Regular'\n",
    "}\n",
    "\n",
    "POSITION_TABLE_FIFA = {\n",
    "    'ST': 'Delantero',\n",
    "    'CM': 'Volante',\n",
    "    'CDM': 'Medio centro defensivo',\n",
    "    'LB': 'Lateral izquierdo',\n",
    "    'GK': 'Portero',\n",
    "    'LM': 'Volante izquierdo',\n",
    "    'RM': 'Volante derecho',\n",
    "    'CAM': 'Volante ofensivo',\n",
    "    'LW': 'Extremo izquierdo',\n",
    "    'LWB': 'Lateral izquierdo ofensivo',\n",
    "    'CB': 'Defensor central',\n",
    "    'RB': 'Lateral derecho',\n",
    "    'RW': 'Extremo derecho',\n",
    "    'RWB': 'Lateral ofensivo derecho',\n",
    "    'CF': 'Media punta'\n",
    "}\n",
    "\n",
    "path = os.path.dirname(os.path.realpath(\".\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesando los datos\n",
    "\n",
    "- Separamos el encabezado de el resto del archivo ya que mas adelante vamos a utilizarlo/modificarlo\n",
    "- Declaramos `all_header` en la que vamos a guardar todos los encabezados y `all_datos` que es la que va a guardar todos los datos de su respectivo archivo (menos el encabezado)\n",
    "- En `all_path_file` vamos a guardar las rutas de los archivos que vamos a procesar. Para esto, utilizamos un  `map` para recorrer la lista con los nombres de los archivos.\n",
    "\n",
    "Leemos los archivos csv, como tenemos un archivo en el que su forma de delimitar los componentes es con `;`, tenemos que poner un condicional para asegurarme de que lo este leyendo, que en este caso es `FIFA-21_Complete.csv`. \n",
    "\n",
    "Para resolver esto, estuvimos pensando en implementar expresiones regulares, pero no podemos ya que `delimiter` solo puede tener un parametro fijo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\\ufefftitle', 'artist', 'top genre', 'year released', 'added', 'bpm', 'nrgy', 'dnce', 'dB', 'live', 'val', 'dur', 'acous', 'spch', 'pop', 'top year', 'artist type'], ['Nombre', 'Ubicación', 'Superficie (km²)', 'Profundidad máxima (m)', 'Profundidad media (m)', 'Coordenadas'], ['\\ufeffplayer_id', 'name', 'nationality', 'position', 'overall', 'age', 'hits', 'potential', 'team']]\n"
     ]
    }
   ],
   "source": [
    "def data_process(path:str):\n",
    "    \"\"\"Separa los datos_spotify del archivo \n",
    "    \"\"\"\n",
    "    all_header:list[list[str]] = [] #Guardo todos los encabezados\n",
    "    all_datos: list[list[list[str]]]= []\n",
    "    all_path_file:list[str] = []\n",
    "    [all_path_file.append(os.path.join(path,\"base_datasets\",name)) for name in NAMES_DATASETS]\n",
    "    for path_name in all_path_file:\n",
    "        with open(path_name,\"r\", encoding=\"utf-8\") as File:  \n",
    "            csv_reader = csv.reader(File, delimiter=';') if (\"FIFA-21_Complete.csv\" in path_name) else csv.reader(File, delimiter=',')\n",
    "            all_header.append(next(csv_reader)) # El encabezado para comparar las columnas borradas\n",
    "            all_datos.append(list(csv_reader))\n",
    "    return all_header,all_datos\n",
    "all_header,all_datos = data_process(path)\n",
    "print(all_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear orden\n",
    "\n",
    "```\n",
    "Crea un orden a partir de dos listas.\n",
    "Ej: hola, chau, bye\n",
    "[0, 1, 2]\n",
    "Y queremos que este en este orden\n",
    "Ej: bye, hola, chau\n",
    "Genera una lista con:\n",
    "[2, 0, 1]\n",
    "```\n",
    "\n",
    "Tenemos una constante que contiene el orden en el que tenemos que dejar las columnas `ORDEN`.\n",
    "\n",
    "- `names_compare` es el orden en el que tienen que quedar las columnas del archivo\n",
    "- `header_compare` es el encabezado del archivo de lectura actual, utilizamos este para identificar el orden de los indices pedidos por la consigna.\n",
    "- utilizamos map y lambda  para pasar los datos de las listas anteriores a minuscula y poder comparar sin tener inconvenientes.\n",
    "- `orden_list` es el orden pedido por la consigna pero en forma de indices para hacer la transferencia de datos mas adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_order(orden_list:list[int],name_remove:list[str],header:list[str]):\n",
    "    names_compare = list(map(lambda x: x.lower(), name_remove))\n",
    "    header_compare = list(map(lambda x: x.lower(), header))\n",
    "    [ orden_list.append(header_compare.index(name)) for name in names_compare]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado de Columnas\n",
    "\n",
    "- Separamos las columnas que queremos mantener de las que vamos a eliminar\n",
    "Para esto, recorremos `ALL_NAMES_REMOVE` que contiene las columnas que quiero conservar para cada archivo. `names_compare` va a tener el las columnas que quiero conservar de un archivo en especifico pero todo en minuscula, para poder compararlo con el encabezado.\n",
    "`header` contiene el encabezado del archivo que quiero comparar (por eso trabajamos siempre con indices) \n",
    "- Generamos sus respectivas listas, con los indices para reutilizar el codigo en un futuro\n",
    "`cols_remove` es una lista que declaramos para poder agregar los indices de manera que queder separados por archivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_cols(all_cols_remove:list[list[int]],all_header:list[list[str]]):\n",
    "    \"\"\"Separa las columnas de las que quiero eliminar\n",
    "    \"\"\"\n",
    "    for index,name_remove in enumerate(ALL_NAMES_REMOVE):\n",
    "        cols_remove:list[int] = []\n",
    "        names_compare = (list(map(lambda x: x.lower(), name_remove))) # Creamos una lista para comparar\n",
    "        header = all_header[index]\n",
    "        for column in header:    # Recorro el encabezado actual\n",
    "            if not(column.lower() in names_compare):\n",
    "                cols_remove.append(header.index(column))\n",
    "        all_cols_remove.append(cols_remove)\n",
    "all_cols_remove:list[list[int]] = []  # Columnas que voy a eliminar [0, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14]  \n",
    "separate_cols(all_cols_remove,all_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenamos Columnas\n",
    "\n",
    "Recorremos todo `row` remplazando sus datos individuales por los datos de las columnas pasadas por parametro, generando el orden pedido  por la consigna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_sorted(row:list[str],orden_list:list[int]): # [0, 1, 2, 3, 4, 5]\n",
    "    \"\"\"Intercambialas posiciones de una lista\n",
    "    \"\"\"   \n",
    "    return [row[indice].replace(row[indice],row[dato]) for indice,dato in enumerate(orden_list)]  # [1, 5, 2, 4, 3, 0]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mayusculas-Minusculas para SPOTIFY\n",
    "\n",
    "- `genders` Con la frase que tenemos (`sentence`), generamos una lista de palabras para poder trabajar en cada una de ellas por separado\n",
    "\n",
    "- Recorremos la lista\n",
    "  - Si se encuentra en la lista, la convertimos toda a mayuscula\n",
    "  - Sino usamos `title()` para pasar la primera a mayuscula\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_words(sentence:str):\n",
    "    \"\"\"Procesa una frase dependiendo de la consigna\"\"\"\n",
    "    genders = sentence.split()\n",
    "    for index,gender in enumerate(genders):\n",
    "        genders[index] = ( gender.upper() if gender.upper() in UPPER_GENDERS_SPOTIFY else gender.title())\n",
    "    sentence = \" \".join(genders)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion para eliminar las columnas\n",
    "\n",
    "Voy recorriendo `cols_remove` y las voy eliminando de `row`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_remove_function(row:list[str],cols_remove:list[int]):\n",
    "    \"\"\"Elimina posiciones de una lista (las posiciones son pasadas por parametro)\"\"\"\n",
    "    for col_index in cols_remove:\n",
    "        del (row[col_index])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion para invertir\n",
    "\n",
    "Invertimos las posiciones de las columnas para eliminarlas desde la ultima, para esto usamos el `sorted(col, reverse=True)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14, 13, 12, 11, 10, 9, 8, 7, 6, 4, 0], [0], [6, 4, 0]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sorted_colls_remove(all_cols_remove:list[list[int]]):\n",
    "    for index,col in enumerate(all_cols_remove):\n",
    "        all_cols_remove[index] = sorted(col, reverse=True) \n",
    "sorted_colls_remove(all_cols_remove)\n",
    "all_cols_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento general de los archivos\n",
    "\n",
    "Buscamos una forma de utilizar el mismo codigo para los tres archivos, para esto , recibimos el archivo por parametro y lo modificamos de la siguiente manera:\n",
    "\n",
    "- Eliminamos todas las columnas que no queremos conservar en el encabezado (`header`) con `cols_remove_function` (ARRIBA ESTAN LOS DETALLES DE LA FUNCIÓN)\n",
    "- Declaramos una lista (que es la que va a contener el orden de los datos) y aplicamos `create_order`, esta funcion nos retorna una lista con los ordenes en que tienen que quedar las columnas, y esta lista la vamos a utilizar para todo el archivo (ARRIBA PARA MAS DETALLES DE LA FUNCIÓN `create_order`)\n",
    "- Por ultimo retornamos la lista con el orden, y el encabezado modigicado para poder insertarlo en el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_order(index:int,header:list[str]):\n",
    "    header=cols_remove_function(header,all_cols_remove[index])\n",
    "    orden_list:list[int] = []  \n",
    "    create_order(orden_list,ALL_ORDEN_REMOVE[index],header)\n",
    "    header = cols_sorted(header,orden_list)\n",
    "    return orden_list,header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potencial\n",
    "\n",
    "Recibimos el potencial del archivo, y lo vamos comparando con un diccionario (que en las claves tiene su potencial en numeros y en valor, su clasificación como jugador) `POTENTIAL_TABLE_FIFA`, cuando el potencial pasado por parametro es mayor, lo remplazo por el valor del diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_replace(potential:str):\n",
    "    compare_potential = int(potential)\n",
    "    for potential_player in POTENTIAL_TABLE_FIFA:\n",
    "        if compare_potential >= potential_player:\n",
    "            potential = POTENTIAL_TABLE_FIFA[potential_player]\n",
    "            break\n",
    "    return potential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remplazar posición\n",
    "\n",
    "- Recibimos la posicion por parametro y la pasamos a español (remplazado el dato con el de una tabla que armamos mas arriba )\n",
    "\n",
    "- En `positions` generamos una lista dividida por `|` para poder modificar cada posición por separado.\n",
    "- Por ultimo, remplazamos los datos con el for y las volvemos a concatenar con `|`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_replace(position:str):\n",
    "    positions = position.split('|')\n",
    "    position = '|'.join([POSITION_TABLE_FIFA[acronym] for acronym in positions])\n",
    "    return position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir coordenadas grados a decimales\n",
    "\n",
    "Si la tenemos en el sistema tradicional de grados, minutos y segundos es necesario convertirla previamente.\n",
    "\n",
    "Para llevar manualmente de grados a decimal sería:\n",
    "\n",
    "- `(23° 08' 06'' N)` = `(23 + (08 / 60) + (06 / 3600)) * 1` = `23.134999`\n",
    "- `(82° 21' 34'' W)` = `(82 + (21 / 60) + (34 / 3600)) * -1` = `-82.359444`\n",
    "\n",
    "- `sign` Guardamos el signo dependiedo de si recibimos la latitud o longitud como parametro\n",
    "- `\"50°14'53\"\"S 72°38'43\"\"O\"` dato recibido por parametro\n",
    "- En la linea 3 separamos los grados de las cordenadas\n",
    "- En la linea 4 separamos los minutos y los segundos de la cordenada.\n",
    "- Por ultimo aplicamos la ecuación y retornamos el resultado.\n",
    "- `round` nos permite limitar el uso de decimales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cordr(coord: str, n_decimals: int = 5) -> str:\n",
    "    sign = -1 if 'S' in coord or 'O' in coord else 1\n",
    "    degree, coord = coord[:-2].split('°')\n",
    "    min, sec = coord.split('\\'')\n",
    "    dd = sign * (int(degree) + int(min)/60 + int(sec)/3600)\n",
    "    return str(round(dd, n_decimals)) + '°'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programa\n",
    "\n",
    "- Recorremos todos los datasets para modificarlos (los nombres estan contenidos en `NAMES_DATASETS`)\n",
    "- Guardamos la ruta en `path_newfile` del archivo actual\n",
    "- Abrimos el archivo en modo de escritura \n",
    "    - Pasamos los datos a `csv_writer`\n",
    "    - `orden_list` contiene el orden en el que van a quedar las columnas\n",
    "    - Escribimos el encabezado en el archivo, ya que lo modificamos aparte\n",
    "    - Despues modificamos las columnas dependiendo del dataset actual\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,name_dataset in enumerate(NAMES_DATASETS):\n",
    "    path_newfile = os.path.join(path, \"processed_datasets\", name_dataset)\n",
    "    with open(path_newfile, \"w\",encoding=\"utf-8\",newline='') as NewFile:\n",
    "        csv_writer = csv.writer(NewFile)\n",
    "        orden_list,new_header=first_order(index,all_header[index])\n",
    "        csv_writer.writerow(new_header)   \n",
    "\n",
    "        if (name_dataset == \"Spotify_2010-2019_Top_100.csv\"):   # Spotify\n",
    "            for row in all_datos[index]:\n",
    "                row = cols_remove_function(row,all_cols_remove[index])\n",
    "                row = cols_sorted(row,orden_list)\n",
    "\n",
    "                row[0] = upper_words(row[0])\n",
    "                csv_writer.writerow(row)\n",
    "                \n",
    "        elif (name_dataset == \"Lagos_Argentina - Hoja_1.csv\"):  # Lagos\n",
    "            for row in all_datos[index]:\n",
    "                row = cols_remove_function(row,all_cols_remove[index])\n",
    "                row = cols_sorted(row,orden_list)\n",
    "\n",
    "                latitude, longitude = row[4].split()\n",
    "                row[4] = transform_cordr(latitude) + ' ' + transform_cordr(longitude)\n",
    "                csv_writer.writerow(row)\n",
    "\n",
    "        elif (name_dataset == \"FIFA-21_Complete.csv\"): # Fifa\n",
    "            for row in all_datos[index]:\n",
    "                row = cols_remove_function(row,all_cols_remove[index])\n",
    "                row = cols_sorted(row,orden_list)\n",
    "\n",
    "                row[4] = potential_replace(row[4]) \n",
    "                row[2] = position_replace(row[2])\n",
    "                csv_writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe3fb9be205b8509bfcfe29f3ee2911db9c3670de4136c9ba4f2c3f3ea984e87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
