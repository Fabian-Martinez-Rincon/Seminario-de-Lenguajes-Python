{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align =\"center\"><img src=\"https://media.giphy.com/media/YjPhjzR0z8qpqtPFyx/giphy.gif\" style = \"height:38px\"/> Procesamiento de los Datasets con Pandas <img src=\"https://media.giphy.com/media/A8ZKGHwM5lWpSqd8rX/giphy.gif\" style = \"height:38px\"/></h1 >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tarjetas de FiguRace se generan a partir de un conjunto de datos que deberán ser preparados previamente. Como parte del proyecto se deberá desarrollar un cuaderno de Jupyter Notebook que extraiga los datos necesarios para el juego de alguno de los datasets provistos y muestre en forma detallada el proceso realizado con los mismos . En el Anexo II se detallan los datasets que deberán utilizar para la aplicación y las modificaciones necesarias para luego guardarlo en un nuevo archivo en formato CSV. El juego deberá cargar esos archivos CSV para funcionar\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td> <h5 align=\"center\"><img src=\"https://media.giphy.com/media/F3IsWfsR1JMyNmL44Z/giphy.gif\" style = \"height:38px\" /> Spotify 2010 - 2019 Top 100 <img  src=\"https://media.giphy.com/media/F3IsWfsR1JMyNmL44Z/giphy.gif\" style = \"height:38px\" /></h5> </td> <td> <h5 align=\"center\"><img src=\"https://media.giphy.com/media/W55QKlBohHZS9RGOWJ/giphy.gif\" style = \"height:38px\" /> FIFA-21 Complete <img  src=\"https://media.giphy.com/media/W55QKlBohHZS9RGOWJ/giphy.gif\" style = \"height:38px\" /></h5> </td><td> <h5 align=\"center\"><img src=\"https://media.giphy.com/media/YOk7USZ9k8yF4R0yn3/giphy.gif\" style = \"height:38px\" /> Lagos Argentina - Hoja 1 <img  src=\"https://media.giphy.com/media/YOk7USZ9k8yF4R0yn3/giphy.gif\" style = \"height:38px\" /></h5> </td>\n",
    "\n",
    "\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    " \n",
    "Deberá adaptar los datos de la siguiente forma: <br>\n",
    "\n",
    "- Poner en `title case` los géneros musicales excepto las siglas EDM, DFW, UK, R&B y LGBTQ+ que deben ir en mayúsculas. Por ejemplo `dfw rap` debe ser transformado a `DFW Rap`.<br>\n",
    "\n",
    "- Considerar también la excepción `k-pop` que debe ser transformada a `K-Pop`.<br>\n",
    "\n",
    "- Se utilizarán como datos de las tarjetas `Top Genre`, `Year Released`, `BPM`, `Top Year` y `Artist Type`. Como dato a adivinar se utilizará `Artist`. Descartar el resto de las columnas.<br>\n",
    "\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Top Genre`, `Artist Type`, `Year Released`, `Top Year`, `BPM` y `Artist`<br>\n",
    "\n",
    "</td>\n",
    "<td>\n",
    " \n",
    "Deberá adaptar los datos de la siguiente forma:<br>\n",
    "\n",
    "- Reemplazar `Potential` por la siguiente escala conceptual:<br>\n",
    "  - Regular: Menos de 60<br>\n",
    "  - Bueno: Entre 60 y 79 (inclusive)<br>\n",
    "  - Muy bueno: Entre 80 y 89 (inclusive)<br>\n",
    "  - Sobresaliente: Desde 90 en adelante.<br>\n",
    "- Reemplazar el valor de `Position` por las posiciones en español. Por ejemplo `LB|CB` debe ser reemplazado por `Defensor izquierdo|Defensor central`<br>\n",
    "- Se utilizarán como datos de las tarjetas: `Age`, `Nationality`, `Position`, `Team` y `Potential`. Como dato a adivinar se utilizará `Name`. Descartar el resto de las columnas.<br>\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Team`, `Nationality`, `Position`, `Age`, `Potential` y `Name`.<br>\n",
    " \n",
    "</td>\n",
    " <td>\n",
    " \n",
    "\n",
    "Deberá adaptar los datos de la siguiente forma:<br>\n",
    "\n",
    "- Transformar las coordenadas en la columna `Coordenadas` a grados decimales.<br>\n",
    "- Se utilizarán como datos de las tarjetas: `Ubicación`, `Superficie (km²)`, `Profundidad máxima (m)`, `Profundidad media (m)`, `Coordenadas`. Como dato a adivinar se utilizará `Nombre`. Descartar el resto de las columnas.<br>\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Ubicación`, `Superficie (km²)`, `Profundidad máxima (m)`, `Profundidad media (m)`, `Coordenadas` y `Nombre`.<br>\n",
    " \n",
    "</td>\n",
    "</tr>\n",
    " \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias a utilizar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constantes a utilizar \n",
    "\n",
    "- En `POTENTIAL_TABLE_FIFA` almacenamos los datos que vamos a remplazar de la columna `potencial`\n",
    "- En `POSITION_TABLE_FIFA` almacenamos los datos que vamos a traducir de la columna `position` \n",
    "- En `UPPER_GENDERS_SPOTIFY` almacenamos los datos a sustituir de la columna `top genre`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "POTENTIAL_TABLE_FIFA = {\n",
    "    90: 'Sobresaliente',\n",
    "    80: 'Muy bueno',\n",
    "    60: 'Bueno',\n",
    "    -1: 'Regular'\n",
    "}\n",
    "\n",
    "POSITION_TABLE_FIFA = {\n",
    "    'ST': 'Delantero',\n",
    "    'CM': 'Volante',\n",
    "    'CDM': 'Medio centro defensivo',\n",
    "    'LB': 'Lateral izquierdo',\n",
    "    'GK': 'Portero',\n",
    "    'LM': 'Volante izquierdo',\n",
    "    'RM': 'Volante derecho',\n",
    "    'CAM': 'Volante ofensivo',\n",
    "    'LW': 'Extremo izquierdo',\n",
    "    'LWB': 'Lateral izquierdo ofensivo',\n",
    "    'CB': 'Defensor central',\n",
    "    'RB': 'Lateral derecho',\n",
    "    'RW': 'Extremo derecho',\n",
    "    'RWB': 'Lateral ofensivo derecho',\n",
    "    'CF': 'Media punta'\n",
    "}\n",
    "\n",
    "UPPER_GENDERS_SPOTIFY = [\"EDM\", \"DFW\", \"UK\", \"R&B\", \"LGBTQ+\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones que transforman columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potencial Fifa\n",
    "\n",
    "Recibimos el potencial del archivo (como estamos trabajando con archivos, nos pasa un string), y lo vamos comparando con un diccionario (que en las claves tiene su potencial en numeros y en valor, su clasificación como jugador) `POTENTIAL_TABLE_FIFA`, cuando el potencial pasado por parametro es mayor, lo remplazo por el valor del diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_replace(potential):\n",
    "    compare_potential = int(potential)\n",
    "    for potential_player in POTENTIAL_TABLE_FIFA:\n",
    "        if compare_potential >= potential_player:\n",
    "            potential = POTENTIAL_TABLE_FIFA[potential_player]\n",
    "            break\n",
    "    return potential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remplazar posición Fifa\n",
    "\n",
    "- Recibimos la posicion por parametro y la pasamos a español (remplazado el dato con el de una tabla que armamos mas arriba )\n",
    "\n",
    "- En `positions` generamos una lista dividida por `|` para poder modificar cada posición por separado.\n",
    "- Por ultimo, remplazamos los datos con el for y las volvemos a concatenar con `|`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_replace(position):\n",
    "    positions = position.split('|')\n",
    "    position = '|'.join([POSITION_TABLE_FIFA[acronym] for acronym in positions])\n",
    "    return position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mayusculas-Minusculas para Spotify\n",
    "\n",
    "- `genders` Con la frase que tenemos (`sentence`), generamos una lista de palabras para poder trabajar en cada una de ellas por separado\n",
    "\n",
    "- Recorremos la lista\n",
    "  - Si se encuentra en la lista, la convertimos toda a mayuscula\n",
    "  - Sino usamos `title()` para pasar la primera a mayuscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_words(sentence):\n",
    "    genders = sentence.split()\n",
    "    for index,gender in enumerate(genders):\n",
    "        genders[index] = ( gender.upper() if gender.upper() in UPPER_GENDERS_SPOTIFY else gender.title())\n",
    "    sentence = \" \".join(genders)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir coordenadas grados a decimales\n",
    "\n",
    "Si la tenemos en el sistema tradicional de grados, minutos y segundos es necesario convertirla previamente.\n",
    "\n",
    "Para llevar manualmente de grados a decimal sería:\n",
    "\n",
    "- `(23° 08' 06'' N)` = `(23 + (08 / 60) + (06 / 3600)) * 1` = `23.134999`\n",
    "- `(82° 21' 34'' W)` = `(82 + (21 / 60) + (34 / 3600)) * -1` = `-82.359444`\n",
    "\n",
    "- `sign` Guardamos el signo dependiedo de si recibimos la latitud o longitud como parametro\n",
    "- `\"50°14'53\"\"S 72°38'43\"\"O\"` dato recibido por parametro\n",
    "- En la linea 3 separamos los grados de las cordenadas\n",
    "- En la linea 4 separamos los minutos y los segundos de la cordenada.\n",
    "- Por ultimo aplicamos la ecuación y retornamos el resultado.\n",
    "- `round` nos permite limitar el uso de decimales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebase_coord(coord, n_decimals = 5):\n",
    "    sign = -1 if 'S' in coord or 'O' in coord else 1\n",
    "    degree, coord = coord[:-2].split('°')\n",
    "    min, sec = coord.split('\\'')\n",
    "    dd = sign * (int(degree) + int(min)/60 + int(sec)/3600)\n",
    "    return str(round(dd, n_decimals)) + '°'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tenemos la misma operación para dos partes de nuestras cordenadas, las separamos, las trabajamos por separado, las concatenamos y por ultimo las retornamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_coords(coords) :\n",
    "    latitude, longitude = coords.split()\n",
    "    coords = rebase_coord(latitude) + ' ' + rebase_coord(longitude)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraciones a aplicar \n",
    "\n",
    "Tenemos un diccionario en el que sus claves son los nombres de los datasets a modificar y sus valores son las caracteristicas que le queremos aplicar a cada dataset\n",
    "\n",
    "- `order` Son las columnas que quiero consevar y el orden preestablecido por el usuario\n",
    "- `translation` La traduccion del encabezado (opcional)\n",
    "- `functions` Las funciones que vamos a aplicar (las clave es la columna y su valor es la funcion que queremos aplicar)\n",
    "- `name` El nuevo nombre de los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATASETS = {                  \n",
    "    'FIFA-21_Complete.csv':{\n",
    "        'order': [\"team\", \"nationality\", \"position\", \"age\", \"potential\" ,\"name\"],\n",
    "        'translation': ['Equipo', 'Nacionalidad', 'Posición', 'Edad', 'Potencial', 'Nombre'],\n",
    "        'functions': {\n",
    "            \"potential\": potential_replace,\n",
    "            \"position\": position_replace\n",
    "            } ,\n",
    "        'name':\"fifa.csv\"     \n",
    "    },\n",
    "    'Lagos_Argentina - Hoja_1.csv':{\n",
    "        'order': [\"Ubicación\", \"Superficie (km²)\", \"Profundidad máxima (m)\", \"Profundidad media (m)\", \"Coordenadas\"],\n",
    "        'functions': {\n",
    "            \"Coordenadas\": transform_coords\n",
    "            },  \n",
    "        \"name\":'lakes.csv'  \n",
    "    },\n",
    "    'Spotify_2010-2019_Top_100.csv':{\n",
    "        'order': [\"top genre\", \"artist type\", \"year released\", \"top year\", \"bpm\" ,\"artist\"],\n",
    "        'translation': ['Top genero', 'Tipo artista', 'Año lanzamiento','Mejor año', 'BPM', 'Artista'],\n",
    "        'functions': {\n",
    "            \"top genre\":upper_words\n",
    "            },\n",
    "        'name':'spotify.csv'       \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rutas a utilizar\n",
    "\n",
    "- `PATH_BASE` Ruta base\n",
    "- `PATH_SOURCE` Ruta de donde leemos los datasets\n",
    "- `PATH_PROSSED` Ruta en donde vamos a procesar los datasets\n",
    "\n",
    "En caso de que no exista la carpeta, la generamos con `makedirs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BASE = os.path.dirname(os.path.dirname(__file__))\n",
    "PATH_SOURCE = os.path.join(PATH_BASE, \"base_datasets\")\n",
    "PATH_PROSSED = os.path.join(PATH_BASE, \"processed_datasets\")\n",
    "if not os.path.exists(PATH_PROSSED):\n",
    "    os.makedirs(PATH_PROSSED, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de un Dataset\n",
    "\n",
    "- Recibimos `file_name` que contiene el nombre del archivo, preguntamos si el nombre se encuentra en nuestro diccionario (asi decidimos si lo procesamos o no)\n",
    "- `file_path` Nos quedamos la ruta en donde se encuentra nuestro df\n",
    "- En `config` como su palabra lo indica, nos quedamos con las configuraciones del df (data frame) a leer  \n",
    "- `processed_path` contiene la dirección con el nuevo nombre de nuestro archivo\n",
    "- Abrimos el archivo en modo escritura\n",
    "    - Dentro del read_csv tenemos:\n",
    "        - El archivo, el delimiter en \"sep\" que python detecta el separador.\n",
    "        - Las columnas a guardar, el tipo de datos que vamos a leer\n",
    "        - E ignoramos las filas que puedan tener algun tipo de error, y utilizamos `error_bad_lines=False` \n",
    "    - Y tomamos una excepcion en caso de que la ruta no exista\n",
    "- En df.dropna eliminamos las columnas vacias\n",
    "- Aplicamos la config `order`\n",
    "- Recorremos la config `functions` y aplicamos su funcion a la columna marcada por su respectiva clave\n",
    "- Preguntamos si tenemos la config `translation`.\n",
    "    - en df.rename() lo que estamos haciendo es mandarle una clave y un valor para que lo remplzace por dicha clave (la traducción)\n",
    "    - En el parametro axis posee 1 ya que solo trabajamos con el encabezado\n",
    "- Reemplazamos todas las celdas vacias por `Desconocido`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(file_name):\n",
    "    if file_name not in DATASETS:\n",
    "        return\n",
    "    file_path = os.path.join(PATH_SOURCE, file_name)\n",
    "    config = DATASETS[file_name]\n",
    "    processed_path = os.path.join(PATH_PROSSED, config['name'])\n",
    "    try:\n",
    "        with open(file_path, mode='r', encoding=\"UTF-8\") as file:\n",
    "            df = pd. read_csv(file, sep=None, engine=\"python\",\n",
    "                              usecols=(config['order']), dtype=str,error_bad_lines=False)\n",
    "    except FileNotFoundError:\n",
    "        print('No existe la ruta', PATH_SOURCE)\n",
    "        return\n",
    "    df.dropna(how=\"all\", inplace=True)\n",
    "\n",
    "    df = df[config['order']]\n",
    "\n",
    "    for columna, function in config['functions'].items():\n",
    "        df[columna] = df[columna].apply(function)\n",
    "    df.fillna('Desconocido',  inplace=True)\n",
    "\n",
    "    df.to_csv(processed_path, mode='w', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busqueda y Procesamiento\n",
    "\n",
    "Tratamos de leer la direcciones y en caso de tener una excepción (que pude ocurrir que mi ruta no coincida con mi carpeta que es `FileNotFoundError` o que mi ruta no sea un directorio `NotADirectoryError`) imprimimos un mensaje con su correspondiente error.\n",
    "\n",
    "- `listdir` nos genera una lista con los nombres de todos los archivos \n",
    "- Iteramos sobre esta lista ya aplicamos nuestra funcion a cada elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    names_files = os.listdir(PATH_SOURCE)\n",
    "    for file_name in names_files:\n",
    "        process_dataset(file_name)\n",
    "except FileNotFoundError:\n",
    "    print('No existe la ruta', PATH_SOURCE)\n",
    "except NotADirectoryError:\n",
    "    print('La ruta no es un directorio ', PATH_SOURCE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80756411583af035d9a6199794371ea696bdbbbc86d4f210b34cb3d9a731db47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
